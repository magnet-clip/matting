{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MattingUNet3, MattingUNetTrainerDistr, get_all_files, MattingDataset\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPARED_FOLDER = Path(\"/media/rustam/data/matting\")\n",
    "train_test_files = get_all_files(PREPARED_FOLDER, 11)\n",
    "print(len(train_test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_files, test_files = train_test_split(train_test_files,  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_files), len(train_files))\n",
    "print(test_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MattingDataset(test_files, max_files=5, th=0.1)\n",
    "for data in a:\n",
    "    matting, seg, image, feats, aoi = data\n",
    "    print(aoi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].imshow(aoi.permute(1,2,0).cpu().numpy())\n",
    "ax[1].imshow(matting.permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as tf\n",
    "\n",
    "\n",
    "REFERENCE_FRAME = 0\n",
    "NUM_POINTS = 4\n",
    "\n",
    "IMAGE_SIZE = (200, 320)\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "transform_train = tf.Compose([\n",
    "    tf.Resize(IMAGE_SIZE),\n",
    "    # tf.RandomPerspective(),\n",
    "    tf.ElasticTransform(),\n",
    "    tf.RandomVerticalFlip(),\n",
    "    tf.RandomHorizontalFlip(),\n",
    "])\n",
    "transform_test = tf.Compose( [ tf.Resize(IMAGE_SIZE) ])\n",
    "\n",
    "model = torch.nn.DataParallel(MattingUNet3(use_sigmoid=True))\n",
    "# model = MattingUNet3(use_sigmoid=True).to(\"cuda:0\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3)\n",
    "l1_loss = nn.L1Loss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'test10'\n",
    "checkpoint = '0109'\n",
    "MAX_FILES = 2000\n",
    "SAVE_EVERY = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MattingUNetTrainerDistr(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    name=NAME,\n",
    "    load=checkpoint,\n",
    "    loss_fn=l1_loss,\n",
    "    save_every=SAVE_EVERY,\n",
    "    test_files=test_files,\n",
    "    train_files=train_files,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    transforms_test=transform_test,\n",
    "    transforms_train=transform_train,\n",
    "    max_files=MAX_FILES,\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    lr=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(trainer.test_losses[10:], label=\"test\")\n",
    "plt.plot(trainer.train_losses[10:], label=\"train\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.mul_lr(0.3)\n",
    "trainer.get_lr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(vision_feats.device)\n",
    "matt, pred = trainer.matting(\"/media/rustam/data/matting/0006-b+\", \"00025\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(15,8))\n",
    "ax[0].imshow(matt)\n",
    "ax[1].imshow(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.mul_lr(0.3)\n",
    "# trainer.set_lr(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(trainer.test_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in model.named_parameters():\n",
    "    if len(q[1]) == 0:\n",
    "        continue\n",
    "    min = q[1].min().item()\n",
    "    max = q[1].max().item()\n",
    "\n",
    "    print(f\"{'!' if min == max else ''}{q[0]}: {tuple(q[1].shape)} {min:0.4f} - {max:0.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
